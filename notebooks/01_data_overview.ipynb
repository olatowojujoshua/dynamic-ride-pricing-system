{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview\n",
    "\n",
    "This notebook provides an overview of the dynamic pricing dataset, including:\n",
    "- Data loading and validation\n",
    "- Basic statistics and distributions\n",
    "- Data quality assessment\n",
    "- Initial insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path().absolute().parent / \"src\"))\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import project modules\n",
    "from src.data.load_data import load_raw_data, validate_data_schema, get_data_summary\n",
    "from src.data.clean import clean_data\n",
    "from src.config import NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_COLUMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the raw dataset\n",
    "try:\n",
    "    df = load_raw_data()\n",
    "    print(f\"Dataset loaded successfully!\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {list(df.columns)}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    # Create sample data if loading fails\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    df = pd.DataFrame({\n",
    "        'Number_of_Riders': np.random.poisson(15, n_samples),\n",
    "        'Number_of_Drivers': np.random.poisson(10, n_samples),\n",
    "        'Location_Category': np.random.choice(['Urban', 'Suburban', 'Rural'], n_samples, p=[0.5, 0.3, 0.2]),\n",
    "        'Customer_Loyalty_Status': np.random.choice(['Silver', 'Gold', 'Platinum'], n_samples, p=[0.4, 0.4, 0.2]),\n",
    "        'Number_of_Past_Rides': np.random.randint(0, 100, n_samples),\n",
    "        'Average_Ratings': np.random.uniform(3.0, 5.0, n_samples),\n",
    "        'Time_of_Booking': np.random.choice(['Morning', 'Afternoon', 'Evening', 'Night'], n_samples),\n",
    "        'Vehicle_Type': np.random.choice(['Economy', 'Premium', 'Luxury'], n_samples, p=[0.6, 0.3, 0.1]),\n",
    "        'Expected_Ride_Duration': np.random.uniform(5, 60, n_samples),\n",
    "        'Historical_Cost_of_Ride': np.random.uniform(10, 100, n_samples)\n",
    "    })\n",
    "    print(\"Created sample data for demonstration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data schema\n",
    "validation_results = validate_data_schema(df)\n",
    "print(\"Data Schema Validation:\")\n",
    "print(f\"Valid: {validation_results['is_valid']}\")\n",
    "\n",
    "if not validation_results['is_valid']:\n",
    "    print(\"Errors:\")\n",
    "    for error in validation_results['errors']:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "if validation_results['warnings']:\n",
    "    print(\"Warnings:\")\n",
    "    for warning in validation_results['warnings']:\n",
    "        print(f\"  - {warning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information\n",
    "print(\"Dataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"First 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Descriptive Statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "missing_df = pd.DataFrame({\n",
    "    'Count': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "display(missing_df[missing_df['Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(\"Removing duplicate rows...\")\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"New shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('Numerical Features Distribution', fontsize=16)\n",
    "\n",
    "numerical_cols = NUMERICAL_FEATURES + [TARGET_COLUMN]\n",
    "\n",
    "for i, col in enumerate(numerical_cols[:6]):\n",
    "    row, col_idx = i // 3, i % 3\n",
    "    axes[row, col_idx].hist(df[col], bins=30, alpha=0.7)\n",
    "    axes[row, col_idx].set_title(col)\n",
    "    axes[row, col_idx].set_xlabel('')\n",
    "    axes[row, col_idx].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Categorical Features Distribution', fontsize=16)\n",
    "\n",
    "for i, col in enumerate(CATEGORICAL_FEATURES[:4]):\n",
    "    row, col_idx = i // 2, i % 2\n",
    "    value_counts = df[col].value_counts()\n",
    "    axes[row, col_idx].bar(value_counts.index, value_counts.values)\n",
    "    axes[row, col_idx].set_title(col)\n",
    "    axes[row, col_idx].set_xlabel('')\n",
    "    axes[row, col_idx].set_ylabel('Count')\n",
    "    axes[row, col_idx].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "numerical_df = df[NUMERICAL_FEATURES + [TARGET_COLUMN]]\n",
    "correlation_matrix = numerical_df.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f')\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target variable\n",
    "target_correlations = correlation_matrix[TARGET_COLUMN].sort_values(key=abs, ascending=False)\n",
    "print(\"Correlation with Target Variable:\")\n",
    "print(target_correlations.drop(TARGET_COLUMN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demand-Supply Analysis\n",
    "df['demand_supply_ratio'] = df['Number_of_Riders'] / (df['Number_of_Drivers'] + 1e-8)\n",
    "\n",
    "print(\"Demand-Supply Analysis:\")\n",
    "print(f\"Average demand/supply ratio: {df['demand_supply_ratio'].mean():.2f}\")\n",
    "print(f\"High demand periods (ratio > 2): {(df['demand_supply_ratio'] > 2).mean():.1%}\")\n",
    "print(f\"Low supply periods (ratio < 0.5): {(df['demand_supply_ratio'] < 0.5).mean():.1%}\")\n",
    "\n",
    "# Price analysis\n",
    "print(f\"\\nPrice Analysis:\")\n",
    "print(f\"Average ride price: ${df[TARGET_COLUMN].mean():.2f}\")\n",
    "print(f\"Price range: ${df[TARGET_COLUMN].min():.2f} - ${df[TARGET_COLUMN].max():.2f}\")\n",
    "print(f\"Price standard deviation: ${df[TARGET_COLUMN].std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location-based analysis\n",
    "location_stats = df.groupby('Location_Category').agg({\n",
    "    TARGET_COLUMN: ['mean', 'std', 'count'],\n",
    "    'Number_of_Riders': 'mean',\n",
    "    'Number_of_Drivers': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Location-based Analysis:\")\n",
    "display(location_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based analysis\n",
    "time_stats = df.groupby('Time_of_Booking').agg({\n",
    "    TARGET_COLUMN: ['mean', 'count'],\n",
    "    'Number_of_Riders': 'mean',\n",
    "    'Number_of_Drivers': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(\"Time-based Analysis:\")\n",
    "display(time_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data cleaning\n",
    "df_clean, cleaning_report = clean_data(df)\n",
    "\n",
    "print(\"Data Cleaning Report:\")\n",
    "print(f\"Original shape: {cleaning_report['original_shape']}\")\n",
    "print(f\"Final shape: {cleaning_report['final_shape']}\")\n",
    "print(f\"Rows removed: {cleaning_report['removed_rows']}\")\n",
    "print(f\"Cleaning steps: {len(cleaning_report['cleaning_steps'])}\")\n",
    "\n",
    "for step in cleaning_report['cleaning_steps']:\n",
    "    print(f\"  - {step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings:\n",
    "1. **Data Quality**: The dataset contains [number] records with [number] features\n",
    "2. **Missing Values**: [summary of missing values]\n",
    "3. **Price Distribution**: [summary of price distribution]\n",
    "4. **Demand-Supply Dynamics**: [key insights about demand-supply ratios]\n",
    "5. **Location Patterns**: [location-based pricing patterns]\n",
    "6. **Time Patterns**: [time-based pricing patterns]\n",
    "\n",
    "### Next Steps:\n",
    "1. Proceed to exploratory data analysis (EDA)\n",
    "2. Feature engineering for price dynamics\n",
    "3. Model development and evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
