{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering for Dynamic Pricing\n",
    "\n",
    "This notebook demonstrates the feature engineering pipeline for dynamic pricing:\n",
    "- Time-based feature extraction\n",
    "- Demand-supply pressure index calculation\n",
    "- Location-based features\n",
    "- Customer behavior features\n",
    "- Interaction features\n",
    "- Feature importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(str(Path().absolute().parent / \"src\"))\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Import project modules\n",
    "from src.data.load_data import load_raw_data\n",
    "from src.data.clean import clean_data\n",
    "from src.features.build_features import build_features, FeatureBuilder\n",
    "from src.features.time_features import extract_time_features, create_time_buckets\n",
    "from src.features.pressure_index import calculate_pressure_index, create_surge_indicators\n",
    "from src.config import NUMERICAL_FEATURES, CATEGORICAL_FEATURES, TARGET_COLUMN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean data\n",
    "df = load_raw_data()\n",
    "df_clean, _ = clean_data(df)\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Cleaned dataset shape: {df_clean.shape}\")\n",
    "print(f\"Target variable: {TARGET_COLUMN}\")\n",
    "\n",
    "# Split for demonstration\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {train_df.shape}\")\n",
    "print(f\"Test set: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-Based Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time features\n",
    "df_time = extract_time_features(train_df.copy())\n",
    "\n",
    "print(\"Time-based features added:\")\n",
    "time_features = [col for col in df_time.columns if col not in train_df.columns]\n",
    "for feature in time_features:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "print(f\"\\nDataset shape after time features: {df_time.shape}\")\n",
    "\n",
    "# Display time feature statistics\n",
    "time_feature_stats = df_time[time_features].describe()\n",
    "display(time_feature_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Time-Based Features Distribution', fontsize=16)\n",
    "\n",
    "# Select numerical time features for visualization\n",
    "numerical_time_features = ['booking_hour', 'hour_sin', 'hour_cos', 'is_rush_hour', 'demand_score', 'time_multiplier']\n",
    "numerical_time_features = [f for f in numerical_time_features if f in df_time.columns]\n",
    "\n",
    "for i, feature in enumerate(numerical_time_features[:6]):\n",
    "    row, col = i // 3, i % 3\n",
    "    if feature in df_time.columns:\n",
    "        df_time[feature].hist(bins=30, ax=axes[row, col], alpha=0.7)\n",
    "        axes[row, col].set_title(feature)\n",
    "        axes[row, col].set_xlabel('')\n",
    "        axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand-Supply Pressure Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pressure index features\n",
    "df_pressure = calculate_pressure_index(df_time.copy())\n",
    "\n",
    "print(\"Pressure index features added:\")\n",
    "pressure_features = [col for col in df_pressure.columns if col not in df_time.columns]\n",
    "for feature in pressure_features:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "print(f\"\\nDataset shape after pressure features: {df_pressure.shape}\")\n",
    "\n",
    "# Display pressure feature statistics\n",
    "pressure_feature_stats = df_pressure[pressure_features].describe()\n",
    "display(pressure_feature_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize pressure features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Pressure Index Features Distribution', fontsize=16)\n",
    "\n",
    "# Select pressure features for visualization\n",
    "key_pressure_features = ['demand_supply_ratio', 'supply_demand_ratio', 'pressure_index', \n",
    "                       'market_imbalance', 'base_surge_multiplier', 'surge_probability']\n",
    "key_pressure_features = [f for f in key_pressure_features if f in df_pressure.columns]\n",
    "\n",
    "for i, feature in enumerate(key_pressure_features[:6]):\n",
    "    row, col = i // 3, i % 3\n",
    "    if feature in df_pressure.columns:\n",
    "        df_pressure[feature].hist(bins=30, ax=axes[row, col], alpha=0.7)\n",
    "        axes[row, col].set_title(feature)\n",
    "        axes[row, col].set_xlabel('')\n",
    "        axes[row, col].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surge Indicator Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create surge indicators\n",
    "df_surge = create_surge_indicators(df_pressure.copy())\n",
    "\n",
    "print(\"Surge indicator features added:\")\n",
    "surge_features = [col for col in df_surge.columns if col not in df_pressure.columns]\n",
    "for feature in surge_features:\n",
    "    print(f\"  - {feature}\")\n",
    "\n",
    "print(f\"\\nDataset shape after surge features: {df_surge.shape}\")\n",
    "\n",
    "# Display surge level distribution\n",
    "if 'surge_level' in df_surge.columns:\n",
    "    print(\"\\nSurge level distribution:\")\n",
    "    print(df_surge['surge_level'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the comprehensive feature builder\n",
    "feature_builder = FeatureBuilder()\n",
    "df_features, _ = build_features(train_df.copy(), fit_transform=True)\n",
    "\n",
    "print(f\"Final feature dataset shape: {df_features.shape}\")\n",
    "print(f\"Total features created: {df_features.shape[1] - 1}\")  # -1 for target\n",
    "\n",
    "# Display feature groups\n",
    "feature_groups = feature_builder.get_feature_importance_groups()\n",
    "print(\"\\nFeature groups:\")\n",
    "for group, features in feature_groups.items():\n",
    "    print(f\"  {group}: {len(features)} features\")\n",
    "    for feature in features[:3]:  # Show first 3\n",
    "        print(f\"    - {feature}\")\n",
    "    if len(features) > 3:\n",
    "        print(f\"    ... and {len(features) - 3} more\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis with target\n",
    "feature_columns = [col for col in df_features.columns if col != TARGET_COLUMN]\n",
    "correlations = df_features[feature_columns + [TARGET_COLUMN]].corr()[TARGET_COLUMN].sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"Top 20 features correlated with target:\")\n",
    "top_correlations = correlations.head(21)[1:]  # Exclude target itself\n",
    "for feature, corr in top_correlations.items():\n",
    "    print(f\"  {feature}: {corr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_15_features = top_correlations.head(15).index\n",
    "correlation_matrix = df_features[list(top_15_features) + [TARGET_COLUMN]].corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, fmt='.2f', cbar_kws={'shrink': 0.8})\n",
    "plt.title('Correlation Matrix of Top Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for feature selection\n",
    "X = df_features[feature_columns]\n",
    "y = df_features[TARGET_COLUMN]\n",
    "\n",
    "# Remove any remaining non-numeric columns\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns\n",
    "X_numeric = X[numeric_features]\n",
    "\n",
    "print(f\"Numeric features for selection: {len(numeric_features)}\")\n",
    "\n",
    "# Univariate feature selection\n",
    "selector = SelectKBest(score_func=f_regression, k=20)\n",
    "X_selected = selector.fit_transform(X_numeric, y)\n",
    "selected_features = numeric_features[selector.get_support()]\n",
    "\n",
    "print(f\"\\nTop 20 selected features:\")\n",
    "feature_scores = selector.scores_[selector.get_support()]\n",
    "for i, (feature, score) in enumerate(zip(selected_features, feature_scores)):\n",
    "    print(f\"  {i+1:2d}. {feature}: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple Random Forest for feature importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Use top selected features\n",
    "X_top = X_numeric[selected_features]\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_top, y)\n",
    "\n",
    "# Get feature importance\n",
    "importance_scores = rf.feature_importances_\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'importance': importance_scores\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Random Forest):\")\n",
    "display(feature_importance.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_15_importance = feature_importance.head(15)\n",
    "\n",
    "plt.barh(range(len(top_15_importance)), top_15_importance['importance'])\n",
    "plt.yticks(range(len(top_15_importance)), top_15_importance['feature'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top 15 Feature Importance (Random Forest)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature engineering summary\n",
    "feature_summary = {\n",
    "    'original_features': len(train_df.columns),\n",
    "    'engineered_features': len(df_features.columns),\n",
    "    'feature_groups': feature_groups,\n",
    "    'top_correlated_features': top_correlations.head(10).to_dict(),\n",
    "    'selected_features': selected_features.tolist(),\n",
    "    'feature_importance': feature_importance.head(10).to_dict('records')\n",
    "}\n",
    "\n",
    "print(\"Feature Engineering Summary:\")\n",
    "print(f\"  Original features: {feature_summary['original_features']}\")\n",
    "print(f\"  Engineered features: {feature_summary['engineered_features']}\")\n",
    "print(f\"  Features created: {feature_summary['engineered_features'] - feature_summary['original_features']}\")\n",
    "\n",
    "print(\"\\nFeature Groups:\")\n",
    "for group, features in feature_summary['feature_groups'].items():\n",
    "    print(f\"  {group}: {len(features)} features\")\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "for i, record in enumerate(feature_summary['feature_importance'][:5]):\n",
    "    print(f\"  {i+1}. {record['feature']}: {record['importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Feature Engineered Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the feature engineered dataset\n",
    "output_path = Path().absolute().parent / \"data\" / \"processed\"\n",
    "output_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Save training features\n",
    "train_features_path = output_path / \"train_features.csv\"\n",
    "df_features.to_csv(train_features_path, index=False)\n",
    "print(f\"Training features saved to: {train_features_path}\")\n",
    "\n",
    "# Save feature builder\n",
    "feature_builder.save_encoders(str(output_path / \"feature_encoders.json\"))\n",
    "print(f\"Feature encoders saved to: {output_path / 'feature_encoders.json'}\")\n",
    "\n",
    "# Apply same transformation to test set\n",
    "test_features = feature_builder.transform(test_df)\n",
    "test_features_path = output_path / \"test_features.csv\"\n",
    "test_features.to_csv(test_features_path, index=False)\n",
    "print(f\"Test features saved to: {test_features_path}\")\n",
    "\n",
    "print(f\"\\nFinal datasets:\")\n",
    "print(f\"  Train: {df_features.shape}\")\n",
    "print(f\"  Test: {test_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Insights\n",
    "\n",
    "### Feature Engineering Results:\n",
    "1. **Time Features**: Successfully extracted cyclical time features, rush hour indicators, and demand scores\n",
    "2. **Pressure Index**: Created comprehensive demand-supply dynamics metrics\n",
    "3. **Surge Indicators**: Developed multi-level surge classification and probability estimates\n",
    "4. **Interaction Features**: Generated location-time, loyalty-pressure, and other interaction terms\n",
    "\n",
    "### Most Important Features:\n",
    "1. [Top feature from analysis]\n",
    "2. [Second most important feature]\n",
    "3. [Third most important feature]\n",
    "\n",
    "### Feature Selection Insights:\n",
    "- [Number of features selected vs total]\n",
    "- [Feature reduction percentage]\n",
    "- [Performance implications]\n",
    "\n",
    "### Recommendations for Modeling:\n",
    "1. Use top 20-30 features for baseline models\n",
    "2. Consider feature groups for interpretable models\n",
    "3. Monitor feature importance drift over time\n",
    "4. Implement feature validation in production"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
